{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining\n",
    "\n",
    "![miners](img/text-miners.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is text mining different? What is text?\n",
    "\n",
    "- Order the words from **SMALLEST** to **LARGEST** units\n",
    " - character\n",
    " - corpora\n",
    " - sentence\n",
    " - word\n",
    " - corpus\n",
    " - paragraph\n",
    " - document\n",
    "\n",
    "(after it is all organized)\n",
    "\n",
    "- Any disagreements about the terms used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "## start small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_test = \"Here is a sentence. Or two, I don't think there will be more.\"\n",
    "token_test_2 = \"i thought this sentence was good.\"\n",
    "token_test_3 = \"Here's a sentence... maybe two. Depending on how you like to count!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Here's a sentence\",\n",
       " '',\n",
       " '',\n",
       " ' maybe two',\n",
       " ' Depending on how you like to count!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's tokenize a document... into sentences\n",
    "def make_sentences(doc):\n",
    "    sentences = doc.split('.')\n",
    "    return sentences\n",
    "\n",
    "make_sentences(token_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Here's\",\n",
       " 'a',\n",
       " 'sentence...',\n",
       " 'maybe',\n",
       " 'two.',\n",
       " 'Depending',\n",
       " 'on',\n",
       " 'how',\n",
       " 'you',\n",
       " 'like',\n",
       " 'to',\n",
       " 'count!']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's tokenize a document into words\n",
    "# with these 3 test cases what would you look out for?\n",
    "def tokenize_it(doc):\n",
    "    tokens = doc.split(' ')\n",
    "    return tokens\n",
    "\n",
    "tokenize_it(token_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New library!\n",
    "\n",
    "while we have seen language processing tools in spark, NLTK is its own python library. And of course, it has its own [documentation](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "resp = requests.get('http://www.gutenberg.org/cache/epub/5200/pg5200.txt')\n",
    "metamorph = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg EBook of Metamorphosis, by Franz Kafka\r\n",
      "Translated by David Wyllie.\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r\n",
      "with this eBook or online at www.gutenberg.net\r\n",
      "\r\n",
      "** This is a COPYRIGHTED Project Gutenberg eBook, Details Below **\r\n",
      "**     Please follow the copyright guidelines in this file.     **\r\n",
      "\r\n",
      "\r\n",
      "Title: Metamorphosis\r\n",
      "\r\n",
      "Author: Franz Kafka\r\n",
      "\r\n",
      "Translator: David Wyllie\r\n",
      "\r\n",
      "Release Date: August 16, 2005 [EBook #5200]\r\n",
      "First posted: May 13, 2002\r\n",
      "Last updated: May 20, 2012\r\n",
      "\r\n",
      "Language: English\r\n",
      "\r\n",
      "\r\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK METAMORPHOSIS ***\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Copyright (C) 2002 David Wyllie.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  Metamorphosis\r\n",
      "  Franz Kafka\r\n",
      "\r\n",
      "Translated by David Wyllie\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "I\r\n",
      "\r\n",
      "\r\n",
      "One morning, when Gregor Samsa woke from troubled dreams, he found\r\n",
      "himself transformed in his bed into a horrible vermin.\n"
     ]
    }
   ],
   "source": [
    "print(metamorph[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your article here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Metamorphosis', 'by', 'Franz', 'Kafka', 'Translated', 'by', 'David', 'Wyllie', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'This', 'is', 'a', 'COPYRIGHTED', 'Project', 'Gutenberg', 'eBook', 'Details', 'Below', 'Please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file', 'Title', 'Metamorphosis', 'Author', 'Franz', 'Kafka', 'Translator', 'David', 'Wyllie', 'Release', 'Date', 'August', 'EBook', 'First', 'posted', 'May', 'Last', 'updated', 'May', 'Language', 'English', 'START', 'OF', 'THIS']\n"
     ]
    }
   ],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "metamorph_tokens_raw = nltk.regexp_tokenize(metamorph, pattern)\n",
    "print(metamorph_tokens_raw[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'metamorphosis', 'by', 'franz', 'kafka', 'translated', 'by', 'david', 'wyllie', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'this', 'is', 'a', 'copyrighted', 'project', 'gutenberg', 'ebook', 'details', 'below', 'please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file', 'title', 'metamorphosis', 'author', 'franz', 'kafka', 'translator', 'david', 'wyllie', 'release', 'date', 'august', 'ebook', 'first', 'posted', 'may', 'last', 'updated', 'may', 'language', 'english', 'start', 'of', 'this']\n"
     ]
    }
   ],
   "source": [
    "metamorph_tokens = [i.lower() for i in metamorph_tokens_raw]\n",
    "print(metamorph_tokens[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/enkeboll/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'metamorphosis', 'franz', 'kafka', 'translated', 'david', 'wyllie', 'ebook', 'use', 'anyone', 'anywhere', 'cost', 'almost', 'restrictions', 'whatsoever', 'may', 'copy', 'give', 'away', 'use', 'terms', 'project', 'gutenberg', 'license', 'included', 'ebook', 'online', 'www', 'gutenberg', 'net', 'copyrighted', 'project', 'gutenberg', 'ebook', 'details', 'please', 'follow', 'copyright', 'guidelines', 'file', 'title', 'metamorphosis', 'author', 'franz', 'kafka', 'translator', 'david', 'wyllie', 'release', 'date', 'august', 'ebook', 'first', 'posted', 'may', 'last', 'updated', 'may', 'language', 'english', 'start', 'project', 'gutenberg', 'ebook', 'metamorphosis', 'copyright', 'c', 'david', 'wyllie', 'metamorphosis', 'franz', 'kafka', 'translated', 'david', 'wyllie', 'one', 'morning', 'gregor', 'samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'back', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "metamorph_tokens_stopped = [w for w in metamorph_tokens if not w in stop_words]\n",
    "print(metamorph_tokens_stopped[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming / Lemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming - Porter Stemmer \n",
    "![porter](https://cdn.homebrewersassociation.org/wp-content/uploads/Baltic_Porter_Feature-600x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "example = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "           'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "           'meeting', 'stating', 'siezing', 'itemization',\n",
    "           'sensational', 'traditional', 'reference', 'colonizer',\n",
    "           'plotted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress\n",
      "fli\n",
      "die\n",
      "mule\n",
      "deni\n",
      "die\n",
      "agre\n",
      "own\n",
      "humbl\n",
      "size\n",
      "meet\n",
      "state\n",
      "siez\n",
      "item\n",
      "sensat\n",
      "tradit\n",
      "refer\n",
      "colon\n",
      "plot\n"
     ]
    }
   ],
   "source": [
    "singles = [stemmer.stem(e) for e in example]\n",
    "print(*singles, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming - Snowball Stemmer\n",
    "![snowball](https://localtvwiti.files.wordpress.com/2018/08/gettyimages-936380496.jpg?quality=85&strip=all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic\n",
      "danish\n",
      "dutch\n",
      "english\n",
      "finnish\n",
      "french\n",
      "german\n",
      "hungarian\n",
      "italian\n",
      "norwegian\n",
      "porter\n",
      "portuguese\n",
      "romanian\n",
      "russian\n",
      "spanish\n",
      "swedish\n"
     ]
    }
   ],
   "source": [
    "print(*SnowballStemmer.languages, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress\n",
      "fli\n",
      "die\n",
      "mule\n",
      "deni\n",
      "die\n",
      "agre\n",
      "own\n",
      "humbl\n",
      "size\n",
      "meet\n",
      "state\n",
      "siez\n",
      "item\n",
      "sensat\n",
      "tradit\n",
      "refer\n",
      "colon\n",
      "plot\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "singles = [stemmer.stem(e) for e in example]\n",
    "print(*singles, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "print(stemmer.stem(\"running\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter vs Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous\n",
      "gener\n"
     ]
    }
   ],
   "source": [
    "print(SnowballStemmer(\"english\").stem(\"generously\"))\n",
    "print(SnowballStemmer(\"porter\").stem(\"generously\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Snowball on metamorphesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'metamorphosi', 'franz', 'kafka', 'translat', 'david', 'wylli', 'ebook', 'use', 'anyon', 'anywher', 'cost', 'almost', 'restrict', 'whatsoev', 'may', 'copi', 'give', 'away', 'use', 'term', 'project', 'gutenberg', 'licens', 'includ', 'ebook', 'onlin', 'www', 'gutenberg', 'net', 'copyright', 'project', 'gutenberg', 'ebook', 'detail', 'pleas', 'follow', 'copyright', 'guidelin', 'file', 'titl', 'metamorphosi', 'author', 'franz', 'kafka', 'translat', 'david', 'wylli', 'releas', 'date', 'august', 'ebook', 'first', 'post', 'may', 'last', 'updat', 'may', 'languag', 'english', 'start', 'project', 'gutenberg', 'ebook', 'metamorphosi', 'copyright', 'c', 'david', 'wylli', 'metamorphosi', 'franz', 'kafka', 'translat', 'david', 'wylli', 'one', 'morn', 'gregor', 'samsa', 'woke', 'troubl', 'dream', 'found', 'transform', 'bed', 'horribl', 'vermin', 'lay', 'armour', 'like', 'back', 'lift', 'head', 'littl', 'could', 'see', 'brown', 'belli']\n"
     ]
    }
   ],
   "source": [
    "meta_stemmed = [stemmer.stem(word) for word in metamorph_tokens_stopped]\n",
    "print(meta_stemmed[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is a short list of additional considerations when cleaning text:\n",
    "\n",
    "- Handling large documents and large collections of text documents that do not fit into memory.\n",
    "- Extracting text from markup like HTML, PDF, or other structured document formats.\n",
    "- Transliteration of characters from other languages into English.\n",
    "- Decoding Unicode characters into a normalized form, such as UTF8.\n",
    "- Handling of domain specific words, phrases, and acronyms.\n",
    "- Handling or removing numbers, such as dates and amounts.\n",
    "- Locating and correcting common typos and misspellings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_stemmed = [w for w in meta_stemmed if w not in ['would', 'could', 'tm', 'gutenberg']]\n",
    "meta_freqdist = FreqDist(meta_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gregor', 298),\n",
       " ('room', 133),\n",
       " ('work', 114),\n",
       " ('even', 104),\n",
       " ('father', 102),\n",
       " ('sister', 101),\n",
       " ('door', 97),\n",
       " ('mother', 90),\n",
       " ('project', 88),\n",
       " ('back', 83),\n",
       " ('one', 76),\n",
       " ('time', 74),\n",
       " ('way', 66),\n",
       " ('look', 61),\n",
       " ('open', 56),\n",
       " ('use', 55),\n",
       " ('get', 52),\n",
       " ('said', 51),\n",
       " ('littl', 49),\n",
       " ('go', 49),\n",
       " ('without', 47),\n",
       " ('first', 45),\n",
       " ('still', 45),\n",
       " ('want', 44),\n",
       " ('like', 43),\n",
       " ('see', 42),\n",
       " ('hand', 41),\n",
       " ('made', 40),\n",
       " ('make', 40),\n",
       " ('head', 39),\n",
       " ('much', 39),\n",
       " ('come', 39),\n",
       " ('day', 38),\n",
       " ('thing', 38),\n",
       " ('move', 38),\n",
       " ('chief', 38),\n",
       " ('thought', 37),\n",
       " ('clerk', 37),\n",
       " ('turn', 36),\n",
       " ('away', 35),\n",
       " ('samsa', 34),\n",
       " ('let', 33),\n",
       " ('bed', 32),\n",
       " ('well', 32),\n",
       " ('went', 32),\n",
       " ('famili', 32),\n",
       " ('left', 32),\n",
       " ('seem', 31),\n",
       " ('soon', 31),\n",
       " ('came', 31)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_freqdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1258bb910>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "meta_freqdist.plot(30, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "## this step happens after we account for stopwords and lemmas; depending on the library...\n",
    "* we make a **Count Vector**, which is the formal term for a **bag of words**\n",
    "* we use vectors to pass text into machine learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the CountVectorizer method on 'basic_example'\n",
    "basic_example = ['The Data Scientist wants to train a machine to train machine learning models.']\n",
    "cv = CountVectorizer()\n",
    "cv.fit(basic_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'models',\n",
       " 'scientist',\n",
       " 'the',\n",
       " 'to',\n",
       " 'train',\n",
       " 'wants']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         1        2       1          1    1   2      2      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what info can we get from cv?\n",
    "# hint -- look at the docs again\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(cv.transform(basic_example).toarray())\n",
    "df.columns = cv.get_feature_names()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization allows us to compare two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to help see what's happening\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fit the CountVectorizer on the 'basic_example', now we transform 'basic_example'\n",
    "example_vector_doc_1 = cv.transform(basic_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# what is the type\n",
    "\n",
    "print(type(example_vector_doc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t2\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t2\n",
      "  (0, 7)\t2\n",
      "  (0, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "# what does it look like\n",
    "\n",
    "print(example_vector_doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         1        2       1          1    1   2      2      1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize it\n",
    "example_vector_df = pd.DataFrame(example_vector_doc_1.toarray(), columns=cv.get_feature_names())\n",
    "example_vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         0        0       0          1    2   0      0      0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we compare new text to the CountVectorizer fit on 'basic_example'\n",
    "new_text = ['the data scientist plotted the residual error of her model']\n",
    "new_data = cv.transform(new_text)\n",
    "new_count = pd.DataFrame(new_data.toarray(),columns=cv.get_feature_names())\n",
    "new_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this the object 'sentences' becomes the corpus\n",
    "sentences = ['The Data Scientist wants to train a machine to train machine learning models.',\n",
    "             'the data scientist plotted the residual error of her model in her analysis',\n",
    "             'Her analysis was so good, she won a Kaggle competition.',\n",
    "             'The machine gained sentience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to the docs for count vectorizer, how would we use an ngram\n",
    "# pro tip -- include stop words\n",
    "bigrams = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x55 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 65 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector = bigrams.fit_transform(sentences)\n",
    "bigram_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 features for this corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['analysis',\n",
       " 'analysis was',\n",
       " 'analysis was so',\n",
       " 'competition',\n",
       " 'data',\n",
       " 'data scientist',\n",
       " 'data scientist plotted',\n",
       " 'data scientist wants',\n",
       " 'error',\n",
       " 'error of']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'There are {str(len(bigrams.get_feature_names()))} features for this corpus')\n",
    "bigrams.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>analysis was</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>data scientist</th>\n",
       "      <th>error</th>\n",
       "      <th>error of</th>\n",
       "      <th>gained</th>\n",
       "      <th>gained sentience</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>to</th>\n",
       "      <th>to train</th>\n",
       "      <th>train</th>\n",
       "      <th>train machine</th>\n",
       "      <th>wants</th>\n",
       "      <th>wants to</th>\n",
       "      <th>was</th>\n",
       "      <th>was so</th>\n",
       "      <th>won</th>\n",
       "      <th>won kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  analysis was  competition  data  data scientist  error  error of  \\\n",
       "0         0             0            0     1               1      0         0   \n",
       "1         1             0            0     1               1      1         1   \n",
       "2         1             1            1     0               0      0         0   \n",
       "3         0             0            0     0               0      0         0   \n",
       "\n",
       "   gained  gained sentience  good  ...  to  to train  train  train machine  \\\n",
       "0       0                 0     0  ...   2         2      2              2   \n",
       "1       0                 0     0  ...   0         0      0              0   \n",
       "2       0                 0     1  ...   0         0      0              0   \n",
       "3       1                 1     0  ...   0         0      0              0   \n",
       "\n",
       "   wants  wants to  was  was so  won  won kaggle  \n",
       "0      1         1    0       0    0           0  \n",
       "1      0         0    0       0    0           0  \n",
       "2      0         0    1       1    1           1  \n",
       "3      0         0    0       0    0           0  \n",
       "\n",
       "[4 rows x 55 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize it\n",
    "bigram_df = pd.DataFrame(bigram_vector.toarray(), columns=bigrams.get_feature_names())\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "## Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing} i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_sentences = ['The Data Scientist wants to train a machine to train machine learning models.',\n",
    "                    'the data scientist plotted the residual error of her model in her analysis',\n",
    "                    'Her analysis was so good, she won a Kaggle competition.',\n",
    "                    'The machine gained sentience']\n",
    "# take out stop words\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "# fit transform the sentences\n",
    "tfidf_sentences = tfidf.fit_transform(tf_idf_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>error</th>\n",
       "      <th>gained</th>\n",
       "      <th>good</th>\n",
       "      <th>kaggle</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>model</th>\n",
       "      <th>models</th>\n",
       "      <th>plotted</th>\n",
       "      <th>residual</th>\n",
       "      <th>scientist</th>\n",
       "      <th>sentience</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610575</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.366739</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  competition      data     error    gained      good    kaggle  \\\n",
       "0  0.000000     0.000000  0.240692  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.325557     0.000000  0.325557  0.412928  0.000000  0.000000  0.000000   \n",
       "2  0.366739     0.465162  0.000000  0.000000  0.000000  0.465162  0.465162   \n",
       "3  0.000000     0.000000  0.000000  0.000000  0.617614  0.000000  0.000000   \n",
       "\n",
       "   learning   machine     model    models   plotted  residual  scientist  \\\n",
       "0  0.305288  0.481384  0.000000  0.305288  0.000000  0.000000   0.240692   \n",
       "1  0.000000  0.000000  0.412928  0.000000  0.412928  0.412928   0.325557   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "3  0.000000  0.486934  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "   sentience     train     wants       won  \n",
       "0   0.000000  0.610575  0.305288  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.465162  \n",
       "3   0.617614  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize it\n",
    "tfidf_df = pd.DataFrame(tfidf_sentences.toarray(), columns=tfidf.get_feature_names())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>analysis was</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>data scientist</th>\n",
       "      <th>error</th>\n",
       "      <th>error of</th>\n",
       "      <th>gained</th>\n",
       "      <th>gained sentience</th>\n",
       "      <th>good</th>\n",
       "      <th>...</th>\n",
       "      <th>to</th>\n",
       "      <th>to train</th>\n",
       "      <th>train</th>\n",
       "      <th>train machine</th>\n",
       "      <th>wants</th>\n",
       "      <th>wants to</th>\n",
       "      <th>was</th>\n",
       "      <th>was so</th>\n",
       "      <th>won</th>\n",
       "      <th>won kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  analysis was  competition  data  data scientist  error  error of  \\\n",
       "0         0             0            0     1               1      0         0   \n",
       "1         1             0            0     1               1      1         1   \n",
       "2         1             1            1     0               0      0         0   \n",
       "3         0             0            0     0               0      0         0   \n",
       "\n",
       "   gained  gained sentience  good  ...  to  to train  train  train machine  \\\n",
       "0       0                 0     0  ...   2         2      2              2   \n",
       "1       0                 0     0  ...   0         0      0              0   \n",
       "2       0                 0     1  ...   0         0      0              0   \n",
       "3       1                 1     0  ...   0         0      0              0   \n",
       "\n",
       "   wants  wants to  was  was so  won  won kaggle  \n",
       "0      1         1    0       0    0           0  \n",
       "1      0         0    0       0    0           0  \n",
       "2      0         0    1       1    1           1  \n",
       "3      0         0    0       0    0           0  \n",
       "\n",
       "[4 rows x 55 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compared to bigrams\n",
    "bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's test out our TfidfVectorizer\n",
    "test_tdidf = tfidf.transform(['this is a test document','look at me I am a test document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a vector\n",
    "test_tdidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf_df = pd.DataFrame(test_tdidf.toarray(), columns=tfidf.get_feature_names())\n",
    "test_tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Similarity Between Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell how similar two documents are to one another, normalizing for size, by taking the cosine similarity of the two. \n",
    "\n",
    "This number will range from [0,1], with 0 being not similar whatsoever, and 1 being the exact same. A potential application of cosine similarity is a basic recommendation engine. If you wanted to recommend articles that are most similar to other articles, you could talk the cosine similarity of all articles and return the highest one.\n",
    "\n",
    "<img src=\"./img/better_cos_similarity.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = CountVectorizer(ngram_range=(1,2))\n",
    "sunday_afternoon = ['I ate a burger at burger queen and it was very good.',\n",
    "                    'I ate a hot dog at burger prince and it was bad',\n",
    "                    'a bad hot dog ate burger prince',\n",
    "                    'I ate a hot dog at burger king and it was bad. I ate a burger at burger queen and it was very good']\n",
    "\n",
    "sample.fit(sunday_afternoon)\n",
    "text_data = sample.transform(sunday_afternoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>and it</th>\n",
       "      <th>at</th>\n",
       "      <th>at burger</th>\n",
       "      <th>ate</th>\n",
       "      <th>ate burger</th>\n",
       "      <th>ate hot</th>\n",
       "      <th>bad</th>\n",
       "      <th>bad ate</th>\n",
       "      <th>bad hot</th>\n",
       "      <th>...</th>\n",
       "      <th>king and</th>\n",
       "      <th>prince</th>\n",
       "      <th>prince and</th>\n",
       "      <th>queen</th>\n",
       "      <th>queen and</th>\n",
       "      <th>very</th>\n",
       "      <th>very good</th>\n",
       "      <th>was</th>\n",
       "      <th>was bad</th>\n",
       "      <th>was very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  and it  at  at burger  ate  ate burger  ate hot  bad  bad ate  \\\n",
       "0    1       1   1          1    1           1        0    0        0   \n",
       "1    1       1   1          1    1           0        1    1        0   \n",
       "2    0       0   0          0    1           1        0    1        0   \n",
       "3    2       2   2          2    2           1        1    1        1   \n",
       "\n",
       "   bad hot  ...  king and  prince  prince and  queen  queen and  very  \\\n",
       "0        0  ...         0       0           0      1          1     1   \n",
       "1        0  ...         0       1           1      0          0     0   \n",
       "2        1  ...         0       1           0      0          0     0   \n",
       "3        0  ...         1       0           0      1          1     1   \n",
       "\n",
       "   very good  was  was bad  was very  \n",
       "0          1    1        0         1  \n",
       "1          0    1        1         0  \n",
       "2          0    0        0         0  \n",
       "3          1    2        1         1  \n",
       "\n",
       "[4 rows x 34 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(text_data.toarray(), columns=sample.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50062617]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# the 0th and 2nd index lines are very different, a number close to 0\n",
    "cosine_similarity(text_data[0],text_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55337157]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 0th and 3rd index lines are very similar, despite different lengths\n",
    "cosine_similarity(text_data[1],text_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84327404]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(text_data[1],text_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06299408]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(text_data[2],text_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get('http://www.gutenberg.org/cache/epub/10571/pg10571.txt')\n",
    "sea = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of The Old Man of the Sea, by W.W. Jacobs\\r\\n\\r\\nThis eBook is for the use '"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sea[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Old', 'Man', 'of', 'the', 'Sea', 'by', 'W', 'W', 'Jacobs', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'Title', 'The', 'Old', 'Man', 'of', 'the', 'Sea', \"Ship's\", 'Company', 'Part', 'Author', 'W', 'W', 'Jacobs', 'Release', 'Date', 'January', 'EBook', 'Language', 'English', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'OLD', 'MAN', 'OF', 'THE', 'SEA', 'Produced', 'by', 'David', 'Widger', 'SHIP', 'S']\n"
     ]
    }
   ],
   "source": [
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "sea_tokens = nltk.regexp_tokenize(sea, pattern)\n",
    "print(sea_tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'old', 'man', 'of', 'the', 'sea', 'by', 'w', 'w', 'jacobs', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'title', 'the', 'old', 'man', 'of', 'the', 'sea', \"ship's\", 'company', 'part', 'author', 'w', 'w', 'jacobs', 'release', 'date', 'january', 'ebook', 'language', 'english', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'the', 'old', 'man', 'of', 'the', 'sea', 'produced', 'by', 'david', 'widger', 'ship', 's']\n"
     ]
    }
   ],
   "source": [
    "sea_tokens = [i.lower() for i in sea_tokens]\n",
    "print(sea_tokens[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'old',\n",
       " 'man',\n",
       " 'sea',\n",
       " 'w',\n",
       " 'w',\n",
       " 'jacob',\n",
       " 'ebook']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sea_stemmed = [stemmer.stem(w) for w in sea_tokens if not w in stop_words]\n",
    "sea_stemmed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = [' '.join(meta_stemmed), ' '.join(sea_stemmed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project ebook metamorphosi franz kafka translat da'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "# fit transform the sentences\n",
    "tfidf_sentences = tfidf.fit_transform(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tfidf_sentences.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abid</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accompani</th>\n",
       "      <th>...</th>\n",
       "      <th>wylli</th>\n",
       "      <th>yank</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yearn</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.049573</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021470</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.012268</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>0.039775</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013976</td>\n",
       "      <td>0.019888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053034</td>\n",
       "      <td>0.03261</td>\n",
       "      <td>0.006629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã 2322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abandon      abid      abil       abl    abrupt   absolut    accent  \\\n",
       "0  0.008621  0.001534  0.002155  0.049573  0.002155  0.006466  0.000000   \n",
       "1  0.000000  0.003315  0.000000  0.000000  0.000000  0.000000  0.004659   \n",
       "\n",
       "     accept    access  accompani  ...     wylli      yank        ye      year  \\\n",
       "0  0.009201  0.018403   0.000000  ...  0.010777  0.002155  0.000000  0.021470   \n",
       "1  0.013258  0.039775   0.009317  ...  0.000000  0.000000  0.013976  0.019888   \n",
       "\n",
       "      yearn       yes  yesterday     young  zealand       zip  \n",
       "0  0.002155  0.012268   0.002155  0.004601  0.00000  0.001534  \n",
       "1  0.000000  0.006629   0.000000  0.053034  0.03261  0.006629  \n",
       "\n",
       "[2 rows x 2322 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27780519]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tfidf_sentences[0], tfidf_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
