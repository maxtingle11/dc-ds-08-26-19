{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining\n",
    "\n",
    "![miners](img/text-miners.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is text mining different? What is text?\n",
    "\n",
    "- Order the words from **SMALLEST** to **LARGEST** units\n",
    " - character\n",
    " - corpora\n",
    " - sentence\n",
    " - word\n",
    " - corpus\n",
    " - paragraph\n",
    " - document\n",
    "\n",
    "(after it is all organized)\n",
    "\n",
    "- Any disagreements about the terms used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "## start small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:16:32.584618Z",
     "start_time": "2019-11-12T16:16:32.582055Z"
    }
   },
   "outputs": [],
   "source": [
    "token_test = \"Here is a sentence. Or two, I don't think there will be more.\"\n",
    "token_test_2 = \"i thought this sentence was good.\"\n",
    "token_test_3 = \"Here's a sentence... maybe two. Depending on how you like to count!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:16:33.481588Z",
     "start_time": "2019-11-12T16:16:33.477495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Here's a sentence\",\n",
       " '',\n",
       " '',\n",
       " ' maybe two',\n",
       " ' Depending on how you like to count!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's tokenize a document... into sentences\n",
    "def make_sentences(doc):\n",
    "    sentences = doc.split('.')\n",
    "    return sentences\n",
    "\n",
    "make_sentences(token_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:16:53.513821Z",
     "start_time": "2019-11-12T16:16:53.508948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sentence.',\n",
       " 'Or',\n",
       " 'two,',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'think',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'more.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's tokenize a document into words\n",
    "# with these 3 test cases what would you look out for?\n",
    "def tokenize_it(doc):\n",
    "    tokens = doc.split(' ')\n",
    "    return tokens\n",
    "\n",
    "tokenize_it(token_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New library!\n",
    "\n",
    "while we have seen language processing tools in spark, NLTK is its own python library. And of course, it has its own [documentation](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:17:55.418276Z",
     "start_time": "2019-11-12T16:17:53.737485Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk # natural language toolkit\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:19:29.285990Z",
     "start_time": "2019-11-12T16:19:28.752477Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "resp = requests.get('http://www.gutenberg.org/cache/epub/5200/pg5200.txt')\n",
    "metamorph = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:20:46.864327Z",
     "start_time": "2019-11-12T16:20:46.860359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg EBook of Metamorphosis, by Franz Kafka\r\n",
      "Translated by David Wyllie.\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r\n",
      "with this eBook or online at www.gutenberg.net\r\n",
      "\r\n",
      "** This is a COPYRIGHTED Project Gutenberg eBook, Details Below **\r\n",
      "**     Please follow the copyright guidelines in this file.     **\r\n",
      "\r\n",
      "\r\n",
      "Title: Metamorphosis\r\n",
      "\r\n",
      "Author: Franz Kafka\r\n",
      "\r\n",
      "Translator: David Wyllie\r\n",
      "\r\n",
      "Release Date: August 16, 2005 [EBook #5200]\r\n",
      "First posted: May 13, 2002\r\n",
      "Last updated: May 20, 2012\r\n",
      "\r\n",
      "Language: English\r\n",
      "\r\n",
      "\r\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK METAMORPHOSIS ***\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Copyright (C) 2002 David Wyllie.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  Metamorphosis\r\n",
      "  Franz Kafka\r\n",
      "\r\n",
      "Translated by David Wyllie\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "I\r\n",
      "\r\n",
      "\r\n",
      "One morning, when Gregor Samsa woke from troubled dreams, he found\r\n",
      "himself transformed in his bed into a horrible vermin.\n"
     ]
    }
   ],
   "source": [
    "print(metamorph[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your article here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:23:55.217927Z",
     "start_time": "2019-11-12T16:23:55.205521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Metamorphosis', 'by', 'Franz', 'Kafka', 'Translated', 'by', 'David', 'Wyllie', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'This', 'is', 'a', 'COPYRIGHTED', 'Project', 'Gutenberg', 'eBook', 'Details', 'Below', 'Please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file', 'Title', 'Metamorphosis', 'Author', 'Franz', 'Kafka', 'Translator', 'David', 'Wyllie', 'Release', 'Date', 'August', 'EBook', 'First', 'posted', 'May', 'Last', 'updated', 'May', 'Language', 'English', 'START', 'OF', 'THIS']\n"
     ]
    }
   ],
   "source": [
    "# use regex tokenizer to split string into list of strings\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\" #regexr.com\n",
    "metamorph_tokens_raw = nltk.regexp_tokenize(metamorph, pattern)\n",
    "print(metamorph_tokens_raw[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:25:19.660415Z",
     "start_time": "2019-11-12T16:25:19.652188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'metamorphosis', 'by', 'franz', 'kafka', 'translated', 'by', 'david', 'wyllie', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'net', 'this', 'is', 'a', 'copyrighted', 'project', 'gutenberg', 'ebook', 'details', 'below', 'please', 'follow', 'the', 'copyright', 'guidelines', 'in', 'this', 'file', 'title', 'metamorphosis', 'author', 'franz', 'kafka', 'translator', 'david', 'wyllie', 'release', 'date', 'august', 'ebook', 'first', 'posted', 'may', 'last', 'updated', 'may', 'language', 'english', 'start', 'of', 'this']\n"
     ]
    }
   ],
   "source": [
    "# make everything lowercase\n",
    "metamorph_tokens = [i.lower() for i in metamorph_tokens_raw]\n",
    "print(metamorph_tokens[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:27:09.227456Z",
     "start_time": "2019-11-12T16:27:07.910067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maxtingle/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:27:49.354809Z",
     "start_time": "2019-11-12T16:27:49.349754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:27:17.660969Z",
     "start_time": "2019-11-12T16:27:17.653641Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'metamorphosis', 'franz', 'kafka', 'translated', 'david', 'wyllie', 'ebook', 'use', 'anyone', 'anywhere', 'cost', 'almost', 'restrictions', 'whatsoever', 'may', 'copy', 'give', 'away', 'use', 'terms', 'project', 'gutenberg', 'license', 'included', 'ebook', 'online', 'www', 'gutenberg', 'net', 'copyrighted', 'project', 'gutenberg', 'ebook', 'details', 'please', 'follow', 'copyright', 'guidelines', 'file', 'title', 'metamorphosis', 'author', 'franz', 'kafka', 'translator', 'david', 'wyllie', 'release', 'date', 'august', 'ebook', 'first', 'posted', 'may', 'last', 'updated', 'may', 'language', 'english', 'start', 'project', 'gutenberg', 'ebook', 'metamorphosis', 'copyright', 'c', 'david', 'wyllie', 'metamorphosis', 'franz', 'kafka', 'translated', 'david', 'wyllie', 'one', 'morning', 'gregor', 'samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armour', 'like', 'back', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly']\n"
     ]
    }
   ],
   "source": [
    "# get rid of words that don't matter\n",
    "stop_words = set(stopwords.words('english'))\n",
    "metamorph_tokens_stopped = [w for w in metamorph_tokens if not w in stop_words]\n",
    "print(metamorph_tokens_stopped[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming / Lemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming - Porter Stemmer \n",
    "![porter](https://cdn.homebrewersassociation.org/wp-content/uploads/Baltic_Porter_Feature-600x800.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:30:36.865097Z",
     "start_time": "2019-11-12T16:30:36.861786Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "example = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "           'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "           'meeting', 'stating', 'siezing', 'itemization',\n",
    "           'sensational', 'traditional', 'reference', 'colonizer',\n",
    "           'plotted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:32:14.432832Z",
     "start_time": "2019-11-12T16:32:14.426354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress\n",
      "fli\n",
      "die\n",
      "mule\n",
      "deni\n",
      "die\n",
      "agre\n",
      "own\n",
      "humbl\n",
      "size\n",
      "meet\n",
      "state\n",
      "siez\n",
      "item\n",
      "sensat\n",
      "tradit\n",
      "refer\n",
      "colon\n",
      "plot\n"
     ]
    }
   ],
   "source": [
    "singles = [stemmer.stem(e) for e in example]\n",
    "print(*singles, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming - Snowball Stemmer\n",
    "![snowball](https://localtvwiti.files.wordpress.com/2018/08/gettyimages-936380496.jpg?quality=85&strip=all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:33:00.011880Z",
     "start_time": "2019-11-12T16:33:00.006699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic\n",
      "danish\n",
      "dutch\n",
      "english\n",
      "finnish\n",
      "french\n",
      "german\n",
      "hungarian\n",
      "italian\n",
      "norwegian\n",
      "porter\n",
      "portuguese\n",
      "romanian\n",
      "russian\n",
      "spanish\n",
      "swedish\n"
     ]
    }
   ],
   "source": [
    "print(*SnowballStemmer.languages, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:33:02.832654Z",
     "start_time": "2019-11-12T16:33:02.829195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "print(stemmer.stem(\"running\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:33:37.386520Z",
     "start_time": "2019-11-12T16:33:37.380667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caress\n",
      "fli\n",
      "die\n",
      "mule\n",
      "deni\n",
      "die\n",
      "agre\n",
      "own\n",
      "humbl\n",
      "size\n",
      "meet\n",
      "state\n",
      "siez\n",
      "item\n",
      "sensat\n",
      "tradit\n",
      "refer\n",
      "colon\n",
      "plot\n"
     ]
    }
   ],
   "source": [
    "singles = [stemmer.stem(e) for e in example]\n",
    "print(*singles, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter vs Snowball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowball is faster than porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:33:09.273487Z",
     "start_time": "2019-11-12T16:33:09.269495Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous\n",
      "gener\n"
     ]
    }
   ],
   "source": [
    "print(SnowballStemmer(\"english\").stem(\"generously\"))\n",
    "print(SnowballStemmer(\"porter\").stem(\"generously\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Snowball on metamorphesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:33:12.816980Z",
     "start_time": "2019-11-12T16:33:12.620232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'metamorphosi', 'franz', 'kafka', 'translat', 'david', 'wylli', 'ebook', 'use', 'anyon', 'anywher', 'cost', 'almost', 'restrict', 'whatsoev', 'may', 'copi', 'give', 'away', 'use', 'term', 'project', 'gutenberg', 'licens', 'includ', 'ebook', 'onlin', 'www', 'gutenberg', 'net', 'copyright', 'project', 'gutenberg', 'ebook', 'detail', 'pleas', 'follow', 'copyright', 'guidelin', 'file', 'titl', 'metamorphosi', 'author', 'franz', 'kafka', 'translat', 'david', 'wylli', 'releas', 'date', 'august', 'ebook', 'first', 'post', 'may', 'last', 'updat', 'may', 'languag', 'english', 'start', 'project', 'gutenberg', 'ebook', 'metamorphosi', 'copyright', 'c', 'david', 'wylli', 'metamorphosi', 'franz', 'kafka', 'translat', 'david', 'wylli', 'one', 'morn', 'gregor', 'samsa', 'woke', 'troubl', 'dream', 'found', 'transform', 'bed', 'horribl', 'vermin', 'lay', 'armour', 'like', 'back', 'lift', 'head', 'littl', 'could', 'see', 'brown', 'belli']\n"
     ]
    }
   ],
   "source": [
    "meta_stemmed = [stemmer.stem(word) for word in metamorph_tokens_stopped]\n",
    "print(meta_stemmed[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is a short list of additional considerations when cleaning text:\n",
    "\n",
    "- Handling large documents and large collections of text documents that do not fit into memory.\n",
    "- Extracting text from markup like HTML, PDF, or other structured document formats.\n",
    "- Transliteration of characters from other languages into English.\n",
    "- Decoding Unicode characters into a normalized form, such as UTF8.\n",
    "- Handling of domain specific words, phrases, and acronyms.\n",
    "- Handling or removing numbers, such as dates and amounts.\n",
    "- Locating and correcting common typos and misspellings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:42:12.176848Z",
     "start_time": "2019-11-12T16:42:12.174428Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:44:24.491877Z",
     "start_time": "2019-11-12T16:44:24.484342Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_stemmed = [w for w in meta_stemmed if w not in ['would', 'could', 'tm', 'gutenberg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:44:25.421705Z",
     "start_time": "2019-11-12T16:44:25.410245Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_freqdist = FreqDist(meta_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:44:27.128961Z",
     "start_time": "2019-11-12T16:44:27.123135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gregor', 298),\n",
       " ('room', 133),\n",
       " ('work', 114),\n",
       " ('even', 104),\n",
       " ('father', 102),\n",
       " ('sister', 101),\n",
       " ('door', 97),\n",
       " ('mother', 90),\n",
       " ('project', 88),\n",
       " ('back', 83),\n",
       " ('one', 76),\n",
       " ('time', 74),\n",
       " ('way', 66),\n",
       " ('look', 61),\n",
       " ('open', 56),\n",
       " ('use', 55),\n",
       " ('get', 52),\n",
       " ('said', 51),\n",
       " ('littl', 49),\n",
       " ('go', 49),\n",
       " ('without', 47),\n",
       " ('first', 45),\n",
       " ('still', 45),\n",
       " ('want', 44),\n",
       " ('like', 43),\n",
       " ('see', 42),\n",
       " ('hand', 41),\n",
       " ('made', 40),\n",
       " ('make', 40),\n",
       " ('head', 39),\n",
       " ('much', 39),\n",
       " ('come', 39),\n",
       " ('day', 38),\n",
       " ('thing', 38),\n",
       " ('move', 38),\n",
       " ('chief', 38),\n",
       " ('thought', 37),\n",
       " ('clerk', 37),\n",
       " ('turn', 36),\n",
       " ('away', 35),\n",
       " ('samsa', 34),\n",
       " ('let', 33),\n",
       " ('bed', 32),\n",
       " ('well', 32),\n",
       " ('went', 32),\n",
       " ('famili', 32),\n",
       " ('left', 32),\n",
       " ('seem', 31),\n",
       " ('soon', 31),\n",
       " ('came', 31)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_freqdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:46:15.383670Z",
     "start_time": "2019-11-12T16:46:15.162571Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1c707fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "meta_freqdist.plot(30, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "## this step happens after we account for stopwords and lemmas; depending on the library...\n",
    "* we make a **Count Vector**, which is the formal term for a **bag of words**\n",
    "* we use vectors to pass text into machine learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:47:03.577711Z",
     "start_time": "2019-11-12T16:47:03.575017Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the [docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:47:28.103399Z",
     "start_time": "2019-11-12T16:47:28.096827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the CountVectorizer method on 'basic_example'\n",
    "basic_example = ['The Data Scientist wants to train a machine to train machine learning models.']\n",
    "cv = CountVectorizer()\n",
    "cv.fit(basic_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:51:35.825565Z",
     "start_time": "2019-11-12T16:51:35.816761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         1        2       1          1    1   2      2      1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what info can we get from cv?\n",
    "# hint -- look at the docs again\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(cv.transform(basic_example).toarray())\n",
    "df.columns = cv.get_feature_names()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization allows us to compare two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:51:42.698773Z",
     "start_time": "2019-11-12T16:51:42.696192Z"
    }
   },
   "outputs": [],
   "source": [
    "# use pandas to help see what's happening\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:51:43.065645Z",
     "start_time": "2019-11-12T16:51:43.062877Z"
    }
   },
   "outputs": [],
   "source": [
    "# we fit the CountVectorizer on the 'basic_example', now we transform 'basic_example'\n",
    "example_vector_doc_1 = cv.transform(basic_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:51:43.529415Z",
     "start_time": "2019-11-12T16:51:43.526409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# what is the type\n",
    "\n",
    "print(type(example_vector_doc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:51:44.227031Z",
     "start_time": "2019-11-12T16:51:44.223584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t2\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t2\n",
      "  (0, 7)\t2\n",
      "  (0, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "# what does it look like\n",
    "\n",
    "print(example_vector_doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:51:45.007183Z",
     "start_time": "2019-11-12T16:51:44.998764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         1        2       1          1    1   2      2      1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize it\n",
    "example_vector_df = pd.DataFrame(example_vector_doc_1.toarray(), columns=cv.get_feature_names())\n",
    "example_vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:51:45.776957Z",
     "start_time": "2019-11-12T16:51:45.767388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>models</th>\n",
       "      <th>scientist</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  learning  machine  models  scientist  the  to  train  wants\n",
       "0     1         0        0       0          1    2   0      0      0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we compare new text to the CountVectorizer fit on 'basic_example'\n",
    "new_text = ['the data scientist plotted the residual error of her model']\n",
    "new_data = cv.transform(new_text)\n",
    "new_count = pd.DataFrame(new_data.toarray(),columns=cv.get_feature_names())\n",
    "new_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:55:01.096349Z",
     "start_time": "2019-11-12T16:55:01.093663Z"
    }
   },
   "outputs": [],
   "source": [
    "# in this the object 'sentences' becomes the corpus\n",
    "sentences = ['The Data Scientist wants to train a machine to train machine learning models.',\n",
    "             'the data scientist plotted the residual error of her model in her analysis',\n",
    "             'Her analysis was so good, she won a Kaggle competition.',\n",
    "             'The machine gained sentience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:59:05.464775Z",
     "start_time": "2019-11-12T16:59:05.462028Z"
    }
   },
   "outputs": [],
   "source": [
    "# go back to the docs for count vectorizer, how would we use an ngram\n",
    "# pro tip -- include stop words\n",
    "bigrams = CountVectorizer(ngram_range=(2, 2)) # (1,3) for range of 1 to 3 grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:59:05.849869Z",
     "start_time": "2019-11-12T16:59:05.844426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x29 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 32 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector = bigrams.fit_transform(sentences)\n",
    "bigram_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:59:07.225184Z",
     "start_time": "2019-11-12T16:59:07.220452Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 features for this corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['analysis was',\n",
       " 'data scientist',\n",
       " 'error of',\n",
       " 'gained sentience',\n",
       " 'good she',\n",
       " 'her analysis',\n",
       " 'her model',\n",
       " 'in her',\n",
       " 'kaggle competition',\n",
       " 'learning models']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'There are {str(len(bigrams.get_feature_names()))} features for this corpus')\n",
    "bigrams.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:59:10.222403Z",
     "start_time": "2019-11-12T16:59:10.206679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis was</th>\n",
       "      <th>data scientist</th>\n",
       "      <th>error of</th>\n",
       "      <th>gained sentience</th>\n",
       "      <th>good she</th>\n",
       "      <th>her analysis</th>\n",
       "      <th>her model</th>\n",
       "      <th>in her</th>\n",
       "      <th>kaggle competition</th>\n",
       "      <th>learning models</th>\n",
       "      <th>...</th>\n",
       "      <th>she won</th>\n",
       "      <th>so good</th>\n",
       "      <th>the data</th>\n",
       "      <th>the machine</th>\n",
       "      <th>the residual</th>\n",
       "      <th>to train</th>\n",
       "      <th>train machine</th>\n",
       "      <th>wants to</th>\n",
       "      <th>was so</th>\n",
       "      <th>won kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis was  data scientist  error of  gained sentience  good she  \\\n",
       "0             0               1         0                 0         0   \n",
       "1             0               1         1                 0         0   \n",
       "2             1               0         0                 0         1   \n",
       "3             0               0         0                 1         0   \n",
       "\n",
       "   her analysis  her model  in her  kaggle competition  learning models  ...  \\\n",
       "0             0          0       0                   0                1  ...   \n",
       "1             1          1       1                   0                0  ...   \n",
       "2             1          0       0                   1                0  ...   \n",
       "3             0          0       0                   0                0  ...   \n",
       "\n",
       "   she won  so good  the data  the machine  the residual  to train  \\\n",
       "0        0        0         1            0             0         2   \n",
       "1        0        0         1            0             1         0   \n",
       "2        1        1         0            0             0         0   \n",
       "3        0        0         0            1             0         0   \n",
       "\n",
       "   train machine  wants to  was so  won kaggle  \n",
       "0              2         1       0           0  \n",
       "1              0         0       0           0  \n",
       "2              0         0       1           1  \n",
       "3              0         0       0           0  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize it\n",
    "bigram_df = pd.DataFrame(bigram_vector.toarray(), columns=bigrams.get_feature_names())\n",
    "bigram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "## Term Frequency - Inverse Document Frequency\n",
    "\n",
    "talking about the importance of each column\n",
    "\n",
    "word frequency in one page vs word frequency in whole document\n",
    "\n",
    "the rarer the word, the more important it is to the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing} i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:03:06.919219Z",
     "start_time": "2019-11-12T17:03:06.913517Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_idf_sentences = ['The Data Scientist wants to train a machine to train machine learning models.',\n",
    "                    'the data scientist plotted the residual error of her model in her analysis',\n",
    "                    'Her analysis was so good, she won a Kaggle competition.',\n",
    "                    'The machine gained sentiance']\n",
    "# take out stop words\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "# fit transform the sentences\n",
    "tfidf_sentences = tfidf.fit_transform(tf_idf_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:03:07.827552Z",
     "start_time": "2019-11-12T17:03:07.824178Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize it\n",
    "tfidf_df = pd.DataFrame(tfidf_sentences.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:03:08.384909Z",
     "start_time": "2019-11-12T17:03:08.367874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>error</th>\n",
       "      <th>gained</th>\n",
       "      <th>good</th>\n",
       "      <th>kaggle</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>model</th>\n",
       "      <th>models</th>\n",
       "      <th>plotted</th>\n",
       "      <th>residual</th>\n",
       "      <th>scientist</th>\n",
       "      <th>sentiance</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610575</td>\n",
       "      <td>0.305288</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.412928</td>\n",
       "      <td>0.325557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.366739</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.465162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  competition      data     error    gained      good    kaggle  \\\n",
       "0  0.000000     0.000000  0.240692  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.325557     0.000000  0.325557  0.412928  0.000000  0.000000  0.000000   \n",
       "2  0.366739     0.465162  0.000000  0.000000  0.000000  0.465162  0.465162   \n",
       "3  0.000000     0.000000  0.000000  0.000000  0.617614  0.000000  0.000000   \n",
       "\n",
       "   learning   machine     model    models   plotted  residual  scientist  \\\n",
       "0  0.305288  0.481384  0.000000  0.305288  0.000000  0.000000   0.240692   \n",
       "1  0.000000  0.000000  0.412928  0.000000  0.412928  0.412928   0.325557   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "3  0.000000  0.486934  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "   sentiance     train     wants       won  \n",
       "0   0.000000  0.610575  0.305288  0.000000  \n",
       "1   0.000000  0.000000  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.465162  \n",
       "3   0.617614  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:03:12.349915Z",
     "start_time": "2019-11-12T17:03:12.336044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis was</th>\n",
       "      <th>data scientist</th>\n",
       "      <th>error of</th>\n",
       "      <th>gained sentience</th>\n",
       "      <th>good she</th>\n",
       "      <th>her analysis</th>\n",
       "      <th>her model</th>\n",
       "      <th>in her</th>\n",
       "      <th>kaggle competition</th>\n",
       "      <th>learning models</th>\n",
       "      <th>...</th>\n",
       "      <th>she won</th>\n",
       "      <th>so good</th>\n",
       "      <th>the data</th>\n",
       "      <th>the machine</th>\n",
       "      <th>the residual</th>\n",
       "      <th>to train</th>\n",
       "      <th>train machine</th>\n",
       "      <th>wants to</th>\n",
       "      <th>was so</th>\n",
       "      <th>won kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis was  data scientist  error of  gained sentience  good she  \\\n",
       "0             0               1         0                 0         0   \n",
       "1             0               1         1                 0         0   \n",
       "2             1               0         0                 0         1   \n",
       "3             0               0         0                 1         0   \n",
       "\n",
       "   her analysis  her model  in her  kaggle competition  learning models  ...  \\\n",
       "0             0          0       0                   0                1  ...   \n",
       "1             1          1       1                   0                0  ...   \n",
       "2             1          0       0                   1                0  ...   \n",
       "3             0          0       0                   0                0  ...   \n",
       "\n",
       "   she won  so good  the data  the machine  the residual  to train  \\\n",
       "0        0        0         1            0             0         2   \n",
       "1        0        0         1            0             1         0   \n",
       "2        1        1         0            0             0         0   \n",
       "3        0        0         0            1             0         0   \n",
       "\n",
       "   train machine  wants to  was so  won kaggle  \n",
       "0              2         1       0           0  \n",
       "1              0         0       0           0  \n",
       "2              0         0       1           1  \n",
       "3              0         0       0           0  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compared to bigrams\n",
    "bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:03:15.011388Z",
     "start_time": "2019-11-12T17:03:15.008012Z"
    }
   },
   "outputs": [],
   "source": [
    "# now let's test out our TfidfVectorizer\n",
    "test_tdidf = tfidf.transform(['this is a test document','look at me I am a test document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:03:15.411221Z",
     "start_time": "2019-11-12T17:03:15.407236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x18 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a vector\n",
    "test_tdidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:03:15.962589Z",
     "start_time": "2019-11-12T17:03:15.944153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>competition</th>\n",
       "      <th>data</th>\n",
       "      <th>error</th>\n",
       "      <th>gained</th>\n",
       "      <th>good</th>\n",
       "      <th>kaggle</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>model</th>\n",
       "      <th>models</th>\n",
       "      <th>plotted</th>\n",
       "      <th>residual</th>\n",
       "      <th>scientist</th>\n",
       "      <th>sentiance</th>\n",
       "      <th>train</th>\n",
       "      <th>wants</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  competition  data  error  gained  good  kaggle  learning  \\\n",
       "0       0.0          0.0   0.0    0.0     0.0   0.0     0.0       0.0   \n",
       "1       0.0          0.0   0.0    0.0     0.0   0.0     0.0       0.0   \n",
       "\n",
       "   machine  model  models  plotted  residual  scientist  sentiance  train  \\\n",
       "0      0.0    0.0     0.0      0.0       0.0        0.0        0.0    0.0   \n",
       "1      0.0    0.0     0.0      0.0       0.0        0.0        0.0    0.0   \n",
       "\n",
       "   wants  won  \n",
       "0    0.0  0.0  \n",
       "1    0.0  0.0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf_df = pd.DataFrame(test_tdidf.toarray(), columns=tfidf.get_feature_names())\n",
    "test_tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Similarity Between Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell how similar two documents are to one another, normalizing for size, by taking the cosine similarity of the two. \n",
    "\n",
    "This number will range from [0,1], with 0 being not similar whatsoever, and 1 being the exact same. A potential application of cosine similarity is a basic recommendation engine. If you wanted to recommend articles that are most similar to other articles, you could talk the cosine similarity of all articles and return the highest one.\n",
    "\n",
    "<img src=\"./img/better_cos_similarity.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:13:05.574468Z",
     "start_time": "2019-11-12T17:13:05.570533Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = CountVectorizer() # can add ngram range parameter\n",
    "sunday_afternoon = ['I ate a burger at burger queen and it was very good.',\n",
    "                    'I ate a hot dog at burger prince and it was bad',\n",
    "                    'I drove a racecar through your kitchen door',\n",
    "                    'I ate a hot dog at burger king and it was bad. I ate a burger at burger queen and it was very good']\n",
    "\n",
    "sample.fit(sunday_afternoon)\n",
    "text_data = sample.transform(sunday_afternoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:13:07.871656Z",
     "start_time": "2019-11-12T17:13:07.865987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# the 0th and 2nd index lines are very different, a number close to 0\n",
    "cosine_similarity(text_data[0],text_data[2])\n",
    "\n",
    "# number close to 0 means nothing alike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:18:20.933628Z",
     "start_time": "2019-11-12T17:18:20.928400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63900965]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# the 0th and 2nd index lines are very different, a number close to 0\n",
    "cosine_similarity(text_data[0],text_data[1])\n",
    "\n",
    "# some similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:13:09.854674Z",
     "start_time": "2019-11-12T17:13:09.849496Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91413793]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 0th and 3rd index lines are very similar, despite different lengths\n",
    "cosine_similarity(text_data[0],text_data[3])\n",
    "\n",
    "# number closer to 1 means more things in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
